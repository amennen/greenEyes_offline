{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nibabel\n",
    "import nilearn\n",
    "from nilearn.image import resample_to_img\n",
    "import matplotlib.pyplot as plt\n",
    "from nilearn import plotting\n",
    "from nilearn.plotting import show\n",
    "from nilearn.plotting import plot_roi\n",
    "from nilearn import image\n",
    "from nilearn.masking import apply_mask\n",
    "# get_ipython().magic('matplotlib inline')\n",
    "import scipy\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from nilearn import image\n",
    "from nilearn.input_data import NiftiMasker\n",
    "#from nilearn import plotting\n",
    "import nibabel\n",
    "from nilearn.masking import apply_mask\n",
    "from nilearn.image import load_img\n",
    "from nilearn.image import new_img_like\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import datasets, svm, metrics\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.cross_validation import LeaveOneLabelOut\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors.nearest_centroid import NearestCentroid\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.feature_selection import SelectFwe\n",
    "from scipy import signal\n",
    "from scipy.fftpack import fft, fftshift\n",
    "from scipy import interp\n",
    "\n",
    "params = {'legend.fontsize': 'large',\n",
    "          'figure.figsize': (5, 3),\n",
    "          'axes.labelsize': 'x-large',\n",
    "          'axes.titlesize': 'x-large',\n",
    "          'xtick.labelsize': 'x-large',\n",
    "          'ytick.labelsize': 'x-large'}\n",
    "font = {'weight': 'bold',\n",
    "        'size': 22}\n",
    "plt.rc('font', **font)\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif, GenericUnivariateSelect, SelectKBest, chi2\n",
    "from sklearn.feature_selection import RFE\n",
    "import os\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import csv\n",
    "from scipy import stats\n",
    "import brainiak\n",
    "import brainiak.funcalign.srm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UPDATED PROJECT DIR & MASKS!!\n",
    "projectDir='/jukebox/norman/amennen/prettymouth_fmriprep2/'\n",
    "DMNmask='/jukebox/norman/amennen/MNI_things/Yeo_JNeurophysiol11_MNI152/Yeo_Network7mask_reoriented_resampledBOLD2.nii.gz'\n",
    "fmriprep_dir=projectDir + '/derivatives/fmriprep'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load subject numbers\n",
    "subInd = 0\n",
    "nsub=38\n",
    "allnames = []\n",
    "allgroups = []\n",
    "groupInfo={}\n",
    "# skip subjects 039 and 116\n",
    "with open(projectDir + 'participants.tsv') as csvDataFile:\n",
    "    csvReader = csv.reader(csvDataFile)\n",
    "    for row in csvReader:\n",
    "        if 'sub' in row[0]:\n",
    "            # now skip the subjects we don't want to analyze\n",
    "            allInfo = row[0].split('\\t')\n",
    "            subjName=allInfo[0]\n",
    "            if subjName != 'sub-039' and subjName != 'sub-116':\n",
    "                if allInfo[3] == 'paranoia':\n",
    "                    group = 0\n",
    "                elif allInfo[3] == 'affair':\n",
    "                    group = 1\n",
    "                allnames.append(subjName)\n",
    "                allgroups.append(group)\n",
    "                subInd+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sub-088', 'sub-089', 'sub-090', 'sub-091', 'sub-092', 'sub-093', 'sub-094', 'sub-095', 'sub-096', 'sub-097', 'sub-098', 'sub-099', 'sub-100', 'sub-101', 'sub-102', 'sub-103', 'sub-104', 'sub-105', 'sub-106', 'sub-107', 'sub-108', 'sub-109', 'sub-110', 'sub-111', 'sub-068', 'sub-081', 'sub-112', 'sub-053', 'sub-113', 'sub-031', 'sub-114', 'sub-115', 'sub-117', 'sub-118', 'sub-119', 'sub-120', 'sub-121', 'sub-122']\n"
     ]
    }
   ],
   "source": [
    "paranoidSubj = allnames[0:19]\n",
    "cheatingSubj = allnames[19:]\n",
    "paranoidLabel = allgroups[0:19]\n",
    "cheatingLabel = allgroups[19:]\n",
    "nfolds=19\n",
    "print(allnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make aggregate data matrix - USED --don't need to run again\n",
    "nVox = 3757\n",
    "nTRs = 475\n",
    "nSub = 38\n",
    "aggregate_masked_data = np.zeros((nVox,nTRs,nSub))\n",
    "for s in np.arange(nsub):\n",
    "   subjName=allnames[s]\n",
    "   subjData=fmriprep_dir + '/' + subjName + '/' + 'func' + '/' + subjName + '_task-prettymouth_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz'\n",
    "   masked_data = apply_mask(subjData, DMNmask)\n",
    "   aggregate_masked_data[:,:,s] = masked_data.T\n",
    "\n",
    "np.save('aggregate_data.npy', aggregate_masked_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_concatenated = np.load('aggregate_data.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_concatenated.dtype # NOT integers--definitely floats!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participants  38\n",
      "Voxels per participant  3757\n",
      "TRs per participant  475\n"
     ]
    }
   ],
   "source": [
    "vox_num, nTR, num_subs = images_concatenated.shape  # Pull out the shape data\n",
    "\n",
    "print('Participants ', num_subs)\n",
    "print('Voxels per participant ', vox_num)\n",
    "print('TRs per participant ', nTR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3757, 475, 38)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(images_concatenated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "test_data = []\n",
    "for sub in range(num_subs):\n",
    "    train_data.append(images_concatenated[:, :, sub])  # Take the first half of TRs as training (The double dash means integer division)\n",
    "    test_data.append(images_concatenated[:, :, sub])  # Take the second half of TRs as testing (The double dash means integer division)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3757, 475)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/jukebox/pkgs/PYGER/beta/lib/python3.6/site-packages/scipy/stats/stats.py:2246: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.expand_dims(sstd, axis=axis))\n"
     ]
    }
   ],
   "source": [
    "# Iterate through the subjects\n",
    "for sub in range(num_subs):\n",
    "    \n",
    "    # Do it for training data\n",
    "    train_data[sub] = stats.zscore(train_data[sub],\n",
    "                                   axis=1,\n",
    "                                   ddof=1)\n",
    "    train_data[sub] = np.nan_to_num(train_data[sub])\n",
    "    \n",
    "    # Do it for test data\n",
    "    test_data[sub] = stats.zscore(test_data[sub],\n",
    "                                  axis=1,\n",
    "                                  ddof=1)\n",
    "    test_data[sub] = np.nan_to_num(test_data[sub])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting SRM, may take a few minutes ...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-c59cb2ed3228>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Fit the SRM data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Fitting SRM, may take a few minutes ...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0msrm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'SRM has been fit'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/jukebox/pkgs/PYGER/beta/lib/python3.6/site-packages/brainiak/funcalign/srm.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    228\u001b[0m                                  \".\")\n\u001b[1;32m    229\u001b[0m         \u001b[0;31m# Run SRM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigma_s_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmu_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrho2_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_srm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/jukebox/pkgs/PYGER/beta/lib/python3.6/site-packages/brainiak/funcalign/srm.py\u001b[0m in \u001b[0;36m_srm\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    474\u001b[0m                     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_diagonal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperturbation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m                     u_subject, s_subject, v_subject = np.linalg.svd(\n\u001b[0;32m--> 476\u001b[0;31m                         a_subject + perturbation, full_matrices=False)\n\u001b[0m\u001b[1;32m    477\u001b[0m                     \u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubject\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mu_subject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv_subject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m                     \u001b[0mrho2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubject\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrace_xtx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubject\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/jukebox/pkgs/PYGER/beta/lib/python3.6/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36msvd\u001b[0;34m(a, full_matrices, compute_uv)\u001b[0m\n\u001b[1;32m   1442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1443\u001b[0m         \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'D->DdD'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'd->ddd'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1444\u001b[0;31m         \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgufunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1445\u001b[0m         \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1446\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_realType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "features = 50  # How many features will you fit?\n",
    "n_iter = 20  # How many iterations of fitting will you perform\n",
    "\n",
    "# Create the SRM object\n",
    "srm = brainiak.funcalign.srm.SRM(n_iter=n_iter, \n",
    "                                 features=features,\n",
    "                                )\n",
    "\n",
    "# Fit the SRM data\n",
    "print('Fitting SRM, may take a few minutes ...')\n",
    "srm.fit(train_data)\n",
    "\n",
    "print('SRM has been fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the shared response\n",
    "print('SRM: Features X Time Points ', srm.s_.shape)\n",
    "plt.figure()\n",
    "plt.title('SRM: Features X Time Points')\n",
    "plt.imshow(srm.s_, cmap='viridis')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the test data into the shared space using the individual weight matrices\n",
    "shared_test = srm.transform(test_data)\n",
    "\n",
    "# Normalize data\n",
    "for subject in range(num_subs):\n",
    "    shared_test[subject] = stats.zscore(shared_test[subject], axis=1, ddof=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.5\n",
      "1\n",
      "0.5\n",
      "2\n",
      "0.5\n",
      "3\n",
      "1.0\n",
      "4\n",
      "1.0\n",
      "5\n",
      "0.5\n",
      "6\n",
      "1.0\n",
      "7\n",
      "1.0\n",
      "8\n",
      "0.5\n",
      "9\n",
      "1.0\n",
      "10\n",
      "0.5\n",
      "11\n",
      "1.0\n",
      "12\n",
      "0.5\n",
      "13\n",
      "0.5\n",
      "14\n",
      "1.0\n",
      "15\n",
      "0.5\n",
      "16\n",
      "1.0\n",
      "17\n",
      "0.5\n",
      "18\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# try first way of converting everyone to a vector\n",
    "accuracy = np.zeros(nfolds)\n",
    "for f in np.arange(nfolds):\n",
    "    testingSubjects = np.array([paranoidSubj[f],cheatingSubj[f]])\n",
    "    testingInd = np.array([f,f+19])\n",
    "    testingLabels = np.array([paranoidLabel[f],cheatingLabel[f]])\n",
    "    indTrain = np.arange(19)\n",
    "    trainingSubjectsInd=np.concatenate([indTrain[:f],indTrain[f+1:]])\n",
    "    #trainingSubjects=[paranoidSubj[j] for j in trainingSubjectsInd]+[cheatingSubj[j] for j in trainingSubjectsInd]\n",
    "    trainingLabels = [paranoidLabel[j] for j in trainingSubjectsInd]+[cheatingLabel[j] for j in trainingSubjectsInd]\n",
    "    s1 = np.arange(19)\n",
    "    s2 = np.arange(19) + 19\n",
    "    trainingInd = [s1[j] for j in trainingSubjectsInd]+[s2[j] for j in trainingSubjectsInd]\n",
    "    clf = LinearSVC()\n",
    "    clf.fit(data_as_vector[trainingInd,:],trainingLabels)\n",
    "    accuracy[f] = clf.score(data_as_vector[testingInd,:],testingLabels)\n",
    "    print(f)\n",
    "    print(accuracy[f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_acc = np.mean(accuracy)\n",
    "print('mean accuracy is @2.2f' % mean_acc)\n",
    "# first try: 73.6 % accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingInd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1, 20])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testingInd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
